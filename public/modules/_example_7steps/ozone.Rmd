
Here's an example R analysis project from start to finish using Ozone monitoring data.

<details>
<summary class="btn_code"> __EXAMPLE__: Ozone data project  **>** </summary>

<div class="quiz" style="margin-top: 0; background-color: white;">

Imagine we just received 3 years worth of ozone monitoring data to summarize. __Fun!__ 

Below is an example workflow we might follow in R.

1. Create a new project
1. Read the data
1. Simplify columns
1. Plot the data
1. Clean the data
1. View the data closer
1. Summarize the data
1. Save the results
1. __Share__ with friends


```{r create, include=F, eval=F, echo=F}
library(readxl)
library(tidyverse)

# Prepare example data
aqs <- read_excel("../data/2014_AQS_FondduLac.xlsx") %>%
       mutate(Date = as.Date(Date))

met <- read_csv("../data/COQ 2014 Processed MET -ASOS.csv") %>% 
       mutate(Date = as.Date(paste(Year, Month, Day, sep = "-")),
              Month = as.numeric(Month),
              Hour = as.numeric(Hour)) %>% 
       group_by(Date, Month, Day, Hour) %>% 
       summarize(TEMP_F = mean(TempF, na.rm = T))

aqs <- left_join(aqs, met)

aqs <- filter(aqs, Parameter == 88101, !is.na(TEMP_F))

aqs <- rename(aqs, OZONE = Conc, YEAR = Year, SITE = site_catid) %>%
       rowwise() %>%
       mutate(YEAR = 2017 - sample(-1:1, 1),
              Date = as.Date(paste(YEAR, Month, Day, sep = "-")))

aqs <- aqs %>%
       select(SITE, Date, Hour, OZONE, TEMP_F, everything()) %>%
       filter(Month > 3, Month < 11) %>% 
       group_by(SITE, Date) %>%
       mutate(OZONE  = max(OZONE, na.rm = T),
              TEMP_F = max(TEMP_F, na.rm = T)) %>% 
       slice(1)

aqs$UNITS <- "PPB"

aqs$UNITS[6] <- "PPM"
aqs$OZONE[6] <- aqs$OZONE[6] / 1000

write_csv(aqs, "../data/OZONE_samples_demo.csv")
```

### 0. Start a new project {-}

We'll name this project: `"2019_Ozone"`


### 1. Read the data {-}
```{r data, message=F, warning=F}
library(readr)

# Read a file from the web
air_data <- read_csv("https://itep-r.netlify.com/data/OZONE_samples_demo.csv")
```

```{r tbl, echo=F}
library(knitr)
library(dplyr)

air_data %>% sample_n(5) %>% select(SITE, Date, OZONE, TEMP_F) %>% kable()
```


### 2. Simplify column names {-}
```{r clean-names, message=F, fig.width=12, fig.height=4}
library(janitor)

# Capital letters and spaces make things more difficult
# Let's clean them out
air_data <- clean_names(air_data)
```


### 3. Plot the data {-}
```{r view, message=F, fig.width=12, fig.height=4}
library(ggplot2)

ggplot(air_data, aes(x = temp_f, y = ozone)) + 
    geom_point(alpha = 0.2) +
    geom_smooth(method = "lm")
```


### 4. Clean the data {-}
```{r clean, eval=T}
library(dplyr)

# Drop values out of range
air_data <- air_data %>% filter(ozone > 0, temp_f < 199) 

# Convert all samples to PPB
air_data <- air_data %>% 
            mutate(OZONE = ifelse(units == "PPM", ozone * 1000, 
                                  ozone)) 
```


### 5. View the data __closer__ {-}
```{r, fig.width=12, fig.height=4}
ggplot(air_data, aes(x = temp_f, y = ozone)) + 
    geom_point(alpha = 0.2, size = 3) +
    geom_smooth(method = "lm") + 
    facet_wrap(~site) +
    labs(title = "Ozone increases with temperature", 
         subtitle = "Observations from 2015-2017")
```


### 6. Summarize the data {-}
```{r summary}
air_data <- air_data %>% 
            group_by(site, year) %>% 
            summarize(avg_ozone = mean(ozone) %>% round(2),
                      avg_temp  = mean(temp_f) %>% round(2))
```


```{r, echo=F}
air_data %>% kable()
```


###  7. Save the results {-}

__Save the data table__
```{r save-csv, eval=F}
air_data %>% write_csv("results/2015_2017_ozone_summary.csv")
```

<br>

__Save the site plot to PDF__
```{r save-pdf, eval=F}
ggsave("results/2015_2017-Ozone vs Temp.pdf")
```


### 8. Share with friends {-}

<a href = "https://github.com/dKvale/ex__OZONE__Project">
![](../images/github_example_ozone.png){style="width: 95%;"}
</a>

<br>
<div class="well">
Having an exact record of your analysis is great documentation for yourself and others. It's also handy when you want to repeat the same analysis on new data. Then you only need to copy the script, update the read data line, and push run to get a whole new set of fancy charts.
</div>

</div>

</details>

<br>
